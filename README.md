# Music-Accompaniment---AI-powered

ğŸµ Music Analyzer â€” AI-Powered Accompaniment Assistant
An AI-powered music analysis tool that converts audio into musical understanding â€” detecting key, tempo, and suggesting scales and chord tones for piano or instrumental accompaniment.
This project combines signal processing, music theory, and machine learning (CNNs) to help musicians quickly find the right harmonic framework to play along with a song.

âœ¨ Features

ğŸ¼ Musical Key Detection
Template-based (chroma + music theory profiles)
Neural networkâ€“based (CNN trained on mel-spectrograms)

ğŸ§  AI Neural Key Classifier
Custom-trained CNN (PyTorch)
24-class classification (12 major + 12 minor)

ğŸ¹ Accompaniment Suggestions
Recommended scales & modes
Target chord tones to emphasize

â± Tempo (BPM) Estimation
Optional beat tracking for rhythmic context

ğŸ§© Modular CLI Design
Switch between template and neural detectors
Clean separation of audio, ML, and theory logic

ğŸ§  How It Works (High Level)

1. Audio Processing
   Load audio (wav/mp3/m4a)
   Normalize & trim
   Extract features:
   Template method â†’ Harmonic chroma
   Neural method â†’ Log mel-spectrogram
2. Key Detection
   Template detector
   Cosine similarity against major/minor key profiles
   Neural detector
   CNN trained on labeled audio clips
   Predicts key probabilities
3. Musical Intelligence
   Select appropriate scales (Ionian, Pentatonic, Dorian, etc.)
   Identify chord tones (1â€“3â€“5 or 1â€“â™­3â€“5)

Output musician-friendly guidance
ğŸ— Project Structure
Music-Analyzer---AI-powered/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ analyze.py # Main CLI entry
â”‚ â”œâ”€â”€ neural_key.py # Neural inference logic
â”‚ â””â”€â”€ **init**.py
â”‚
â”œâ”€â”€ ml/
â”‚ â”œâ”€â”€ scripts/
â”‚ â”‚ â”œâ”€â”€ dataset.py # Audio â†’ mel dataset
â”‚ â”‚ â”œâ”€â”€ model.py # CNN architecture
â”‚ â”‚ â”œâ”€â”€ train.py # Training loop
â”‚ â”‚ â””â”€â”€ test_dataset.py
â”‚ â”œâ”€â”€ data/ # (ignored) training audio
â”‚ â”œâ”€â”€ models/ # (ignored) checkpoints
â”‚ â””â”€â”€ runs/
â”‚
â”œâ”€â”€ input/ # Example audio files
â”œâ”€â”€ out/ # Analysis reports
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸš€ Installation (macOS + VSCode)
git clone https://github.com/Tinle0301/Music-Analyzer---AI-powered.git
cd Music-Analyzer---AI-powered

python3 -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt
Optional (recommended for audio decoding):
brew install ffmpeg

â–¶ï¸ Usage
Template-based key detection
python3 -m src.analyze input/song.m4a --auto-bpm
Neural (AI) key detection
python3 -m src.analyze input/song.m4a \
 --auto-bpm \
 --detector neural \
 --ckpt ml/models/key_cnn_best.pt
Output example
Detected key: E major
Relative minor: C# minor
Estimated BPM: 112

Recommended scales:

1. Major (Ionian)
2. Major Pentatonic

Target notes: E, G#, B
A report is also saved to:
out/song_report.txt

ğŸ§ª Training the Neural Model
Prepare a manifest:
ml/data/manifest.tsv

Example:
ml/data/audio/track001.m4a E major
ml/data/audio/track002.m4a C# minor

Train:
python3 -m ml.scripts.train --epochs 20 --batch_size 8

Checkpoints are saved to:
ml/models/key_cnn_best.pt

ğŸ›  Tech Stack
Python 3.12
PyTorch â€” neural network training & inference
Librosa â€” audio feature extraction
NumPy / SciPy â€” signal processing
Scikit-learn â€” dataset splitting
GitHub â€” version control & PR workflow

ğŸ¯ Learning Outcomes
Audio feature engineering (mel, chroma)
CNN design for timeâ€“frequency data
Music theory applied to AI systems
Real-world ML training & inference pipeline
Professional GitHub workflow (branches, PRs)

ğŸ¹ MIDI chord export for GarageBand
ğŸŒ YouTube â†’ audio ingestion
ğŸ§  Ensemble (template + neural fusion)
ğŸ“ˆ Training on large datasets (GTZAN, GiantSteps)
ğŸ¼ Sheet music generation (MusicXML)
ğŸ“œ License
MIT License
